# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['imagesearch', 'imagesearch.cli']

package_data = \
{'': ['*']}

install_requires = \
['attrs>=19.3.0,<20.0.0', 'imagehash>=4.1.0,<5.0.0', 'tqdm>=4.48.2,<5.0.0']

entry_points = \
{'console_scripts': ['imagesearch = imagesearch.__main__:main']}

setup_kwargs = {
    'name': 'imagesearch',
    'version': '0.4.1',
    'description': 'Measure visual similiarity of a reference image to other images.',
    'long_description': '# imagesearch\n\n![PyPI](https://img.shields.io/pypi/v/imagesearch)\n![Build](https://github.com/t-mart/imagesearch/workflows/Build/badge.svg?branch=master)\n[![Coverage Status](https://coveralls.io/repos/github/t-mart/imagesearch/badge.svg?branch=master)](\nhttps://coveralls.io/github/t-mart/imagesearch?branch=master)\n![PyPI - Python Version](https://img.shields.io/pypi/pyversions/imagesearch)\n\n`imagesearch` performs visual comparison operations on images.\n\nThe `compare` command measures visual similiarity between a reference image and a set of other\nimages. This can be used to search for a similar image that you know among a deep directory\nstructure of images that you don\'t want to manually scan.\n\nThe `dupe` command finds images which have identical visual fingerprints in a search path. This\ncan be used to identify images which you can delete later.\n\n## Installation\n\n    pip install imagesearch\n\nSee [imagesearch on PyPI](https://pypi.org/project/imagesearch/).\n\n## Examples\n\n- Get help:\n\n        > imagesearch --help\n        ...\n\n## Commands\n\n`imagesearch` functionality is broken up into subcommands provided on the command line.\n\nWhile the subcommands may have unique arguments, others are common among them:\n\n- Algorithm arguments, which specify which fingerprint algorithm to use. For help in choosing, see\n  the section below. For example, to use "average hashing", specify `--ahash`. **If no algorithm is\n  specified, `--dhash` is implied.**\n\n  - These algorithms can take in additional parameters to tune their performance. See the help\n    output for what these parameters are. They should be given in a comma-separated list, joining\n    each argument name to its value with an equals sign. For example:\n\n    ```\n    > imagesearch dupe images/ --whash --algo-params hash_size=8,mode=db4\n    > imagesearch dupe --help  # for more detail\n    ```\n\n- `-f`/`-format` specifies the output format of results. This can be either `text` or `json` (the\n  default). `json` should be used when the results are to be read by another program because\n  eccentricities in filenames will be properly encoded. _(All examples below use `text` for\n  clarity.)_\n\n### `search` Command\n\n**A `0` value indicates the highest level of similarity, or possibly a true match.**\n\n- Compare a reference image to all images in a search path:\n\n        > imagesearch search needle.jpg haystack\\ --format text\n        28      haystack\\0.jpg\n        38      haystack\\1.jpg\n        12      haystack\\2.jpg\n        18      haystack\\3.jpg\n        32      haystack\\4.jpg\n        29      haystack\\5.jpg\n        0       haystack\\6.jpg\n        29      haystack\\7.jpg\n        5       haystack\\8.jpg\n        28      haystack\\9.jpg\n\n    In this example, `haystack\\6.jpg` is most similar.\n\n- Compare against a single image:\n\n        > imagesearch search needle.jpg haystack\\1.jpg --format text\n        38       haystack\\1.jpg\n\n- Only return images with similarity less than or equal to 10:\n\n        > imagesearch search needle.jpg haystack\\ --threshold 10 --format text\n        0       haystack\\6.jpg\n        5       haystack\\8.jpg\n\n- Return the first image found under the threshold (0, in this case) and stop searching immediately:\n\n        > imagesearch search needle.jpg haystack\\ -t 0 --stop-on-first-match --format text\n        0       haystack\\6.jpg\n\n- Specify a different algorithm:\n\n        > imagesearch search needle.jpg haystack\\ --colorhash --format text\n        ...\n\n- Get more help:\n\n        > imagesearch search --help\n        ...\n\n### `dupe` Command\n\n- Find all visually similar images in a search path:\n\n        > imagesearch dupe images\\ --format text\n        fff7db9f03030203\n                images\\file-123.jpg\n                images\\deep\\subdir\\foo.jpeg\n        fcf8f0fae2c6c400\n                images\\a\\file-987.jpg\n                images\\subdir\\bar.png\n\n    Each set of paths that are similar is prefixed with its hash.\n\n- Get more help:\n\n        > imagesearch dupe --help\n        ...\n\n## Visual Similiarity\n\nAt its core, `imagesearch` creates image fingerprints and compares them to other fingerprints. A\ncritical feature of these fingerprints is that they can be numerically compared. **Images that are\ndifferent will have large differences in their fingerprints, and vice versa.**\n\nUnless you have a good understanding of the algorihms used, values should be treated as opaque and\nsubjective. It is dependent on the algorithm used to create the fingerprints and your criteria for\nwhat "similar" is.\n\nThis project uses the\n[imagehash](https://github.com/JohannesBuchner/imagehash) library to produce these fingerprints, and\nmore information about the techniques can be found there.\n\n## Algorithms\n\nAll the fingerprinting algorithms in `imagesearch` come from\n[imagehash](https://github.com/JohannesBuchner/imagehash). In `imagesearch`, you may specify which\nalgorithm to use by giving an argument in one of the following forms:\n\n- `--ahash`: Average hashing (aHash)\n- `--phash`: 2-axis perceptual hashing (pHash)\n- `--phash-simple`: 1-axis perceptual hashing (pHash)\n- `--dhash`: Horizontal difference hashing (dHash)\n- `--dhash-vert`: Vertical difference hashing (dHash)\n- `--whash`: Wavelet hashing (wHash), can specify either Haar (`mode=haar`) or Daubechies\n  (`mode=db4`)\n- `--colorhash`: HSV color hashing (colorhash)\n\n## Collisions\nThese algorithms trade away accuracy for speed and size, usually with acceptable results. Instead of\nproducing an artifact that exactly identifies an image, there\'s analysis done on some more abstract\nquality of the image, such as it\'s luminance or\n[signal frequency](https://en.wikipedia.org/wiki/Discrete_cosine_transform). This allows us\nto:\n- do less processing\n- get a fingerprint with a small size\n- get a fingerprint that exists in a linear space for comparison\n\nHowever, because the exact image analysis is abstract and produces a fixed-size fingerprint, it\'s\nabsolutely possible for 2 different images to have the same fingerprint.\n\nThis is sort of an analog to cryptographic hash collosions, so it\'s important to understand what\nkinds of scenarios may cause this!\n\nSee\n[this section of the imagehash documentation](\nhttps://github.com/JohannesBuchner/imagehash#example-results) for examples of different images that\nproduce the same fingerprint. The source code of that project also references other pages that\nexplain the workings of the algorithm.\n\n### Tuning\nIf you notice collisions for images you expect to hash differently, try changing the algorithm\nparameters. One easy way to do this is to increase the hash size, done for example by:\n\n```\nimagesearch dupe images/ --dhash --algo-params hash_size=16\n```\n\nSee the subcommand help for more details and any constraints that may be on the value.\n\n# Contributing\n\n## Features TODO\n\n- whitelist file paths by extension (currently tries to open every file in the path, which\n  hurts for directories with other big files in them. Not sure if `PIL.Image.open` is smart enough\n  to failfast on unknown data.) Something like `--ext .jpg --ext .png --ext .jpeg`.\n  - set whitelist of popular extensions with something like `--only-popular-extensions`.\n- asyncio for reading? look at `aiofile` project and Image.open(BytesIO(...data...)). Would this\n  even help though? Is there harddisk read parallelism to leverage?\n- algorithm parameter parsing uses it\'s own little sublanguage (comma-separated key=value pairs).\n  This could be a first-order argparse task instead. Would have to inspect each `Algorithm` and\n  auto-generate acceptable arguments. `argparse.ArgumentParser` has a nice `parse_known_args`\n  method that could chomp away at non-algorithm-specific arguments first, and then parse\n  algorithm-specific ones once the algorithm is known. How would we generate help text for this\n  though?\n\n## Bug Fixes/Features\n\nSubmit a PR from an appropriately named feature branch off of master.\n\n## Releasing\n\n1. Bump the version with `poetry run bumpversion [patch|minor|major]`. This will update the version\nnumber around the project, commit and tag it.\n2. Push the repo. A Github release will be made and published to PyPI.\n',
    'author': 'Tim Martin',
    'author_email': 'tim@timmart.in',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/t-mart/imagesearch',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<4.0',
}


setup(**setup_kwargs)
