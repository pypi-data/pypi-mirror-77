Metadata-Version: 2.1
Name: neural-structured-learning
Version: 1.3.1
Summary: Neural Structured Learning is an open-source TensorFlow framework to train neural networks with structured signals
Home-page: https://github.com/tensorflow/neural-structured-learning
Author: Google LLC
License: UNKNOWN
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 2
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Description-Content-Type: text/plain
Requires-Dist: absl-py
Requires-Dist: attrs
Requires-Dist: scipy
Requires-Dist: six

Neural Structured Learning (NSL) is a new learning paradigm to train neural
networks by leveraging structured signals in addition to feature inputs.
Structure can be explicit as represented by a graph or implicit as induced
by adversarial perturbation.

Structured signals are commonly used to represent relations or similarity
among samples that may be labeled or unlabeled. Leveraging these signals
during neural network training harnesses both labeled and unlabeled data,
which can improve model accuracy, particularly when the amount of labeled
data is relatively small. Additionally, models trained with samples that are
generated by adversarial perturbation have been shown to be robust against
malicious attacks, which are designed to mislead a model's prediction or
classification.

NSL generalizes to Neural Graph Learning as well as to Adversarial Learning.
The NSL framework in TensorFlow provides the following easy-to-use APIs and
tools for developers to train models with structured signals:

* Keras APIs to enable training with graphs (explicit structure) and
  adversarial perturbations (implicit structure).

* TF ops and functions to enable training with structure when using
  lower-level TensorFlow APIs.

* Tools to build graphs and construct graph inputs for training.

The NSL framework is designed to be flexible and can be used to train any
kind of neural network. For example, feed-forward, convolution, and
recurrent neural networks can all be trained using the NSL framework. In
addition to supervised and semi-supervised learning (a low amount of
supervision), NSL can in theory be generalized to unsupervised learning.
Incorporating structured signals is done only during training, so the
performance of the serving/inference workflow remains unchanged.

