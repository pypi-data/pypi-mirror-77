Metadata-Version: 2.1
Name: datacube
Version: 1.8.3
Summary: An analysis environment for satellite and other earth observation data
Home-page: https://github.com/opendatacube/datacube-core
Author: Open Data Cube
Maintainer: Open Data Cube
Maintainer-email: 
License: Apache License 2.0
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Natural Language :: English
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: POSIX
Classifier: Operating System :: POSIX :: BSD
Classifier: Operating System :: POSIX :: Linux
Classifier: Operating System :: Microsoft :: Windows
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Topic :: Scientific/Engineering :: GIS
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Requires-Python: >=3.6.0
Description-Content-Type: text/x-rst
Requires-Dist: affine
Requires-Dist: pyproj (>=2.5)
Requires-Dist: shapely (>=1.6.4)
Requires-Dist: cachetools
Requires-Dist: click (>=5.0)
Requires-Dist: cloudpickle (>=0.4)
Requires-Dist: dask[array]
Requires-Dist: distributed
Requires-Dist: jsonschema
Requires-Dist: netcdf4
Requires-Dist: numpy
Requires-Dist: psycopg2
Requires-Dist: lark-parser (>=0.6.7)
Requires-Dist: python-dateutil
Requires-Dist: pyyaml
Requires-Dist: rasterio (>=1.0.2)
Requires-Dist: sqlalchemy
Requires-Dist: toolz
Requires-Dist: xarray (>=0.9)
Provides-Extra: all
Requires-Dist: Sphinx ; extra == 'all'
Requires-Dist: boto3 ; extra == 'all'
Requires-Dist: bottleneck ; extra == 'all'
Requires-Dist: celery (>=4) ; extra == 'all'
Requires-Dist: ciso8601 ; extra == 'all'
Requires-Dist: compliance-checker (>=4.0.0) ; extra == 'all'
Requires-Dist: dask[distributed] ; extra == 'all'
Requires-Dist: distributed ; extra == 'all'
Requires-Dist: fiona ; extra == 'all'
Requires-Dist: hypothesis ; extra == 'all'
Requires-Dist: matplotlib ; extra == 'all'
Requires-Dist: mock ; extra == 'all'
Requires-Dist: moto ; extra == 'all'
Requires-Dist: paramiko ; extra == 'all'
Requires-Dist: pycodestyle ; extra == 'all'
Requires-Dist: pylint ; extra == 'all'
Requires-Dist: pytest ; extra == 'all'
Requires-Dist: pytest-cov ; extra == 'all'
Requires-Dist: pytest-httpserver ; extra == 'all'
Requires-Dist: pytest-timeout ; extra == 'all'
Requires-Dist: recommonmark ; extra == 'all'
Requires-Dist: redis ; extra == 'all'
Requires-Dist: setuptools ; extra == 'all'
Requires-Dist: setuptools-scm[toml] ; extra == 'all'
Requires-Dist: sphinx-click ; extra == 'all'
Requires-Dist: sphinx-autodoc-typehints ; extra == 'all'
Requires-Dist: sphinx-rtd-theme ; extra == 'all'
Requires-Dist: sshtunnel ; extra == 'all'
Requires-Dist: tqdm ; extra == 'all'
Provides-Extra: celery
Requires-Dist: celery (>=4) ; extra == 'celery'
Requires-Dist: redis ; extra == 'celery'
Provides-Extra: cf
Requires-Dist: compliance-checker (>=4.0.0) ; extra == 'cf'
Provides-Extra: dev
Requires-Dist: Sphinx ; extra == 'dev'
Requires-Dist: boto3 ; extra == 'dev'
Requires-Dist: bottleneck ; extra == 'dev'
Requires-Dist: ciso8601 ; extra == 'dev'
Requires-Dist: dask[distributed] ; extra == 'dev'
Requires-Dist: distributed ; extra == 'dev'
Requires-Dist: hypothesis ; extra == 'dev'
Requires-Dist: mock ; extra == 'dev'
Requires-Dist: moto ; extra == 'dev'
Requires-Dist: paramiko ; extra == 'dev'
Requires-Dist: pycodestyle ; extra == 'dev'
Requires-Dist: pylint ; extra == 'dev'
Requires-Dist: pytest ; extra == 'dev'
Requires-Dist: pytest-cov ; extra == 'dev'
Requires-Dist: pytest-httpserver ; extra == 'dev'
Requires-Dist: pytest-timeout ; extra == 'dev'
Requires-Dist: recommonmark ; extra == 'dev'
Requires-Dist: setuptools ; extra == 'dev'
Requires-Dist: setuptools-scm[toml] ; extra == 'dev'
Requires-Dist: sphinx-click ; extra == 'dev'
Requires-Dist: sphinx-autodoc-typehints ; extra == 'dev'
Requires-Dist: sphinx-rtd-theme ; extra == 'dev'
Requires-Dist: sshtunnel ; extra == 'dev'
Requires-Dist: tqdm ; extra == 'dev'
Provides-Extra: distributed
Requires-Dist: distributed ; extra == 'distributed'
Requires-Dist: dask[distributed] ; extra == 'distributed'
Provides-Extra: doc
Requires-Dist: Sphinx ; extra == 'doc'
Requires-Dist: sphinx-rtd-theme ; extra == 'doc'
Requires-Dist: sphinx-autodoc-typehints ; extra == 'doc'
Requires-Dist: sphinx-click ; extra == 'doc'
Requires-Dist: recommonmark ; extra == 'doc'
Requires-Dist: setuptools ; extra == 'doc'
Requires-Dist: setuptools-scm[toml] ; extra == 'doc'
Provides-Extra: interactive
Requires-Dist: matplotlib ; extra == 'interactive'
Requires-Dist: fiona ; extra == 'interactive'
Provides-Extra: performance
Requires-Dist: ciso8601 ; extra == 'performance'
Requires-Dist: bottleneck ; extra == 'performance'
Provides-Extra: replicas
Requires-Dist: paramiko ; extra == 'replicas'
Requires-Dist: sshtunnel ; extra == 'replicas'
Requires-Dist: tqdm ; extra == 'replicas'
Provides-Extra: s3
Requires-Dist: boto3 ; extra == 's3'
Provides-Extra: test
Requires-Dist: hypothesis ; extra == 'test'
Requires-Dist: mock ; extra == 'test'
Requires-Dist: pycodestyle ; extra == 'test'
Requires-Dist: pylint ; extra == 'test'
Requires-Dist: pytest ; extra == 'test'
Requires-Dist: pytest-cov ; extra == 'test'
Requires-Dist: pytest-timeout ; extra == 'test'
Requires-Dist: pytest-httpserver ; extra == 'test'
Requires-Dist: moto ; extra == 'test'

Open Data Cube Core
===================

|Build Status| |Coverage Status| |Documentation Status|

Overview
========

The Open Data Cube Core provides an integrated gridded data
analysis environment for decades of analysis ready earth observation
satellite and related data from multiple satellite and other acquisition
systems.

Documentation
=============

See the `user guide <http://datacube-core.readthedocs.io/en/latest/>`__ for
installation and usage of the datacube, and for documentation of the API.

`Join our Slack <http://slack.opendatacube.org>`__ if you need help
setting up or using the Open Data Cube.

Please help us to keep the Open Data Cube community open and inclusive by
reading and following our `Code of Conduct <code-of-conduct.md>`__.

Requirements
============

System
~~~~~~

-  PostgreSQL 9.5+
-  Python 3.6+

Developer setup
===============

1. Clone:

   -  ``git clone https://github.com/opendatacube/datacube-core.git``

2. Create a Python environment to use ODC within, we recommend `conda <https://docs.conda.io/en/latest/miniconda.html>`__ as the
   easiest way to handle Python dependencies.

::

   conda create -n odc -c conda-forge python=3.6 datacube pre_commit
   conda activate odc

3. Install a develop version of datacube-core.

::

   cd datacube-core
   pip install --upgrade -e .

4. Install the `pre-commit <https://pre-commit.com>`__ hooks to help follow ODC coding
   conventions when committing with git.

::

   pre-commit install

5. Run unit tests + PyLint
   ``./check-code.sh``

   (this script approximates what is run by Travis. You can
   alternatively run ``pytest`` yourself). Some test dependencies may need to be installed, attempt to install these using:

   ``pip install --upgrade -e '.[test]'``

   If install for these fails please lodge them as issues.

6. **(or)** Run all tests, including integration tests.

   ``./check-code.sh integration_tests``

   -  Assumes a password-less Postgres database running on localhost called

   ``agdcintegration``

   -  Otherwise copy ``integration_tests/agdcintegration.conf`` to
      ``~/.datacube_integration.conf`` and edit to customise.


Alternatively one can use ``opendatacube/datacube-tests`` docker image to run
tests. This docker includes database server pre-configured for running
integration tests. Add ``--with-docker`` command line option as a first argument
to ``./check-code.sh`` script.

::

   ./check-code.sh --with-docker integration_tests


Developer setup on Ubuntu
~~~~~~~~~~~~~~~~~~~~~~~~~

Building Python virtual environment on Ubuntu suitable for development work.

Install dependencies:

::

   sudo apt-get update
   sudo apt-get install -y \
     autoconf automake build-essential make cmake \
     graphviz \
     python3-venv \
     python3-dev \
     libpq-dev \
     libyaml-dev \
     libnetcdf-dev \
     libudunits2-dev


Building python virtual environment:

::

   pyenv="${HOME}/.envs/odc"  # Change to suit your needs
   mkdir -p "${pyenv}"
   python3 -m venv "${pyenv}"
   source "${pyenv}/bin/activate"
   pip install -U pip wheel cython numpy
   pip install -e '.[dev]'
   pip install flake8 mypy pylint autoflake black


.. |Build Status| image:: https://github.com/opendatacube/datacube-core/workflows/build/badge.svg
   :target: https://github.com/opendatacube/datacube-core/actions
.. |Coverage Status| image:: https://codecov.io/gh/opendatacube/datacube-core/branch/develop/graph/badge.svg
   :target: https://codecov.io/gh/opendatacube/datacube-core
.. |Documentation Status| image:: https://readthedocs.org/projects/datacube-core/badge/?version=latest
   :target: http://datacube-core.readthedocs.org/en/latest/


