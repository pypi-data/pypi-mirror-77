{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dask with fMKS\n",
    "\n",
    "fMKS is currently being developed with Dask support. Currently the `generate_cahn_hilliard_data` function generates data using Dask. This is an embarrisegly parallel workflow as typically for MKS many Cahn-Hilliard simulations are required to calibrate the model. The following is tested using both the threaded and multiprocessing schedulers. Currently the author can not get the distributed scheduler working. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "from fmks.data.cahn_hilliard import generate_cahn_hilliard_data\n",
    "import dask.threaded\n",
    "import dask.multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `time_ch` calls `generate_cahn_hilliard_data` to generate the data. `generate_cahn_hilliard_data` returns the microstructure and response as a tuple. `compute` is called on the response field with certain number of workers and with a scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_ch(num_workers,\n",
    "            get,\n",
    "            shape=(48, 200, 200),\n",
    "            chunks=(1, 200, 200),\n",
    "            n_steps=100):\n",
    "    generate_cahn_hilliard_data(shape,\n",
    "                                chunks=chunks,\n",
    "                                n_steps=n_steps)[1].compute(num_workers=num_workers,\n",
    "                                                            get=get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threaded Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 thread(s)\n",
      "1 loop, best of 3: 7.15 s per loop\n",
      "4 thread(s)\n",
      "1 loop, best of 3: 9.87 s per loop\n",
      "2 thread(s)\n",
      "1 loop, best of 3: 17.9 s per loop\n",
      "1 thread(s)\n",
      "1 loop, best of 3: 33.6 s per loop\n"
     ]
    }
   ],
   "source": [
    "for n_proc in (8, 4, 2, 1):\n",
    "    print(n_proc, \"thread(s)\")\n",
    "    %timeit time_ch(n_proc, dask.threaded.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 process(es)\n",
      "1 loop, best of 3: 6.41 s per loop\n",
      "4 process(es)\n",
      "1 loop, best of 3: 9.24 s per loop\n",
      "2 process(es)\n",
      "1 loop, best of 3: 17.6 s per loop\n",
      "1 process(es)\n",
      "1 loop, best of 3: 34.2 s per loop\n"
     ]
    }
   ],
   "source": [
    "for n_proc in (8, 4, 2, 1):\n",
    "    print(n_proc, \"process(es)\")\n",
    "    %timeit time_ch(n_proc, dask.multiprocessing.get)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
