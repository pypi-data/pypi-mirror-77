{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running importance analysis with Python API\n",
    "=====================================\n",
    "\n",
    "This is an *VariantSpark* example notebook.\n",
    "\n",
    "\n",
    "One of the main applications of VariantSpark is discovery of genomic variants correlated with a response variable (e.g. case vs control) using random forest gini importance.\n",
    "\n",
    "The `chr22_1000.vcf` is a very small sample of the chromosome 22 VCF file from the 1000 Genomes Project.\n",
    "\n",
    "`chr22-labels.csv` is a CSV file with sample response variables (labels). In fact the labels directly represent the number of alternative alleles for each sample at a specific genomic position. E.g.: column 22_16050408 has labels derived from variants in chromosome 22 position 16050408. We would expect then that position 22:16050408 in the VCF file is strongly correlated with the label 22_16050408.\n",
    "\n",
    "Both data sets are located in the `..\\data` directory.\n",
    "\n",
    "This notebook demonstrates how to run importance analysis on these data with *VariantSpark* Python API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Create a `VarsparkContext` using `SparkSession` object (here injected as `spark`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from varspark import VarsparkContext\n",
    "vc = VarsparkContext(spark, silent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load the features `fs` and labels `ls` from data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vc.import_vcf('../data/chr22_1000.vcf')\n",
    "labels = vc.load_label('../data/chr22-labels.csv', '22_16050408')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Run the importance analysis and retrieve top important variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = features.importance_analysis(labels, seed = 13, n_trees=500, batch_size=20)\n",
    "top_variables = ia.important_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable\tImportance\n",
      "22_16050408\t0.000863450363985\n",
      "22_16051107\t0.000784308342255\n",
      "22_16053197\t0.000653021887401\n",
      "22_16051480\t0.000632510000666\n",
      "22_16050678\t0.000595007893431\n",
      "22_16052656\t0.000563403500509\n",
      "22_16051882\t0.000552010380163\n",
      "22_16053435\t0.000532201151905\n",
      "22_16053797\t0.000502325268641\n",
      "22_16052838\t0.000482158614379\n"
     ]
    }
   ],
   "source": [
    "print(\"%s\\t%s\" % ('Variable', 'Importance'))\n",
    "for var_and_imp in top_variables:\n",
    "    print(\"%s\\t%s\" % var_and_imp)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on using *VariantSpark* and the Python API please visit the [documentation](http://variantspark.readthedocs.io/en/latest/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
